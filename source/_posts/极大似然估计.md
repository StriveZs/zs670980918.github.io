---
title: 极大似然估计

categories:
  - Math

tag:
  - 极大似然估计
---

# 极大似然估计
## 贝叶斯决策
首先来看贝叶斯分类, 贝叶斯公式如下：  

![figure.1](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20venlwNTIxL3VwbG9hZF9pbWFnZS9yYXcvbWFzdGVyL0F4bjdhSy5wbmc?x-oss-process=image/format,png)

其中 **p(w) 为先验概率**，表示每种类别分布的概率; **p(x|w)为类条件概率**, 表示在某种类别w的前提下, 某件事情x发生的概率; 而P(w|x) 为后验概率，表示某事x发生了，并且它属于某一类别w的概率，有了这个后验概率，我们就可以对样本进行分类。**后验概率越大，说明某事物属于这个类别的可能性越大，我们越有理由把它x归到这个类别w下。**  

这样我们就可以根绝p(w) p(x) p(x|w)来计算出p(w|x)从而得到x的类别划分.

## 问题引出
但是在实际问题中并不都是这样幸运的, 我们能获得的数据可能只有有限数目的样本数据，而++先验概率p(w)和类条件概率（各类的总体分布）p(x|w)都是未知的++.根据仅有的样本数据进行分类时，一种可行的办法是我们需要先对先验概率和类条件概率进行评估，然后在套用贝叶斯分类器。

**先验概率的估计较简单**:1.每个样本所属的自然状态都是已知的（有点监督学习）2.依靠经验 3.用训练样本中各类出现的频率估计

类条件概率的估计很难，原因包括：1.概率密度函数包含了一个随机变量的全部信息；2.样本数据可能不多；3.特征向量x的维度可能很大等等  
总之要直接估计类条件概率的密度函数很难。解决办法：**把估计完全未知的概率密度 p(x|w)转换为估计参数。这样就将概率密度估计问题转化为了参数估计问题** ==极大似然估计就是一种参数估计方法==。 当然，概率密度函数的选取很重要，模型正确，在样本区域无穷时，我们会得到较准的估计值，如果模型都错了，那估计半天的参数，肯定没有意义了。

## 重要前提
**训练样本的分布能代表样本的真实分布。每个样本集中的样本都是所谓++独立同分布额随机变量++，且有充分的训练样本。**

## 极大似然估计
原理图：

![figure.2](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20venlwNTIxL3VwbG9hZF9pbWFnZS9yYXcvbWFzdGVyL0VrUTU5Yy5wbmc?x-oss-process=image/format,png)

**似然函数(likehood function)** : 联合概率密度函数 $p(D|\theta)$ 称为相对于$\left\{ x_{1},x_{2},\dots ,x_{N} \right\}$ 的$\theta$的似然函数. 每个x都是独立的

$$ l(\theta)=p(D|\theta)=p(x_{1},x_{2},\dots,x_{N}|\theta)=\prod_{i=1}^{N}p(x_{i}|\theta) $$

如果 $\hat{\theta}$ 是参数空间中能使似然函数 $l(\theta)$ 最大的 $\theta$ 值，则$\hat{\theta}$应该是最可能的参数值，那么$\hat{\theta}$ 就是 $\theta$ 的极大似然估计量。它的样本集的函数记作：  

$$ \hat{\theta}=d(x_{1},x_{2},\dots,x_{N})=d(D)$$

$$ \hat{\theta}=d(x_{1},x_{2},\dots,x_{N}) $$ 称为极大似然函数估计值

## 求解极大似然函数
**ML估计**:求是的出现该组样本的概率最大的 $\theta$ 值。

$$ \hat{\theta}=arg\: \underset{\theta}{max} \prod_{i=1}^{N}p(x_{i}|\theta)$$

实际中为了便于分析，定义了**对数似然函数**：

$$ H(\theta)=ln\:l(\theta)$$

$$ l(\theta)=p(D|\theta)=p(x_{1},x_{2},\dots,x_{N}|\theta)=\prod_{i=1}^{N}p(x_{i}|\theta) $$

$$ \hat{\theta}=arg\:H(\theta)=arg\: \underset{\theta}{max} \ln l(\theta)= arg\: \prod_{i=1}^{N}ln\:p(x_{i}|\theta)$$

1.未知参数只有一个（theta为标量）  
在似然函数满足联系、可微的正则条件下，极大似然估计量是下面微分方程的解：

![figure.3](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20venlwNTIxL3VwbG9hZF9pbWFnZS9yYXcvbWFzdGVyL0FZSU1vaC5wbmc?x-oss-process=image/format,png)

2.未知参数有多个(theta为向量)  
则theta可表示为具有S个分量的未知向量：

$$ \theta=[\theta_{1},\theta_{2},\dots,\theta_{s}]^{T} $$

记梯度算子：

![figure.4](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20venlwNTIxL3VwbG9hZF9pbWFnZS9yYXcvbWFzdGVyLzh6aVJkaC5wbmc?x-oss-process=image/format,png)

若似然函数满足连续可导的条件，则最大似然估计量就是如下方程的解.

![figure.5](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20venlwNTIxL3VwbG9hZF9pbWFnZS9yYXcvbWFzdGVyL2RQbG0xaS5wbmc?x-oss-process=image/format,png)

方程的解只是一个估计值，只有在样本数趋于无限多的时候，它才会接近于真实值，

## 例子

![figure.6](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20venlwNTIxL3VwbG9hZF9pbWFnZS9yYXcvbWFzdGVyL0RvdTNHRC5wbmc?x-oss-process=image/format,png)

## 总结
**求解最大似然估计量的一般步骤：**
- 写出似然函数
- 写出对数似然函数，并整理
- 求对数似然函数关于标量/向量theta的导数，在上面例子中theta为向量=(u,sigma)
- 求解似然方程，将求导后的结果等于0 （满足dH(theta)/d theta=0