---
title: 机器学习之k-邻近算法
url: 538.html
id: 538
categories:
  - k-邻近算法
  - 文章页
  - 机器学习
date: 2018-04-07 11:28:07
tags:
  - Machine Learning
  - KNN
  - Algorithm
---

![](http://47.100.4.8/wp-content/uploads/2018/04/timg.jpg) K-邻近算法 简单地说，k-邻近算法采用测量不同特征值之间的距离方法进行分类。   优点：精度高，对异常值不敏感，无数据输入假定。 缺点：计算复杂度高，空间复杂度高。 适应数据范围：数值型和标称型。   工作原理：存在一个样本数据集合，也称训练样本集，并且样本集中每个数据都存在标签，即我们知道样本集中每一个数据与所属分类的对应关系。当输入一个没有标签的新数据后，将新数据的每一个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据（即最近邻的标签）的分类标签。 一般来说只选择样本数据集中前k个最相似的数据，通常k是不大于20的整数。 最后选择k个最相似的数据中出现次数最多的数据，作为新数据的分类。   k-邻近算法的一般流程： ① 收集数据：可以使用任何方法。 ② 准备数据：距离计算所需数据要得数值，最好是结构化的数据格式。 ③ 分析数据：可以使用任何方法。 ④ 训练算法：此步骤不适用于k-邻近算法。 ⑤ 测试算法：计算错误率。 ⑥ 使用算法：首先需要输入样本数据和结构化的输出结果，然后运行k-邻近算法判定 输入数据分别属于哪个分类，最后应用对计算出的分类执行后续的处理。   kNN算法的伪代码： ① 计算已知类别数据集中的点的每一个点依次执行以下操作： ② 按照距离递增次序排序 ③ 选取与当前点距离最小的k个点 ④ 确定前k个点所在类别的出现频率 ⑤ 返回当前k个点出现频率最高的类别作为当前点的预测分类 使用欧式距离公式计算两点间的距离：0ρ = sqrt( (x1-x2)^2+(y1-y2)^2 ) （其实就是大家所知的计算两点间的那个距离公式）  上面的式子是针对两个特征值进行计算 如果是三个特征值那么就是 0ρ = sqrt( (x1-x2)^2+(y1-y2)^2+(z1+z2)^2)  同理四个特征值也是。 核心算法： ![](http://47.100.4.8/wp-content/uploads/2018/04/kn.png)   End！